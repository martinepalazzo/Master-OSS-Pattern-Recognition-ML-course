{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "__Universite de Technologie de Troyes__<br/>\n",
    "__Universidad Tecnologica Nacional Buenos Aires__<br/>\n",
    "__Master OSS__<br/>\n",
    "__Machine Learning & Pattern Recognition__<br/>\n",
    "__Practice Sessions__<br/>\n",
    "__Teacher: Martin Palazzo__\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some visualizations in this notebook have been adapted from Raschka, S. (2015). Python machine learning. Packt publishing ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining decision functions with Bayes and Likelihood ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define useful funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define de values of a normal PDF \n",
    "def normal_pdf(x, mu, sigma):\n",
    "    return (1.0 / ( np.sqrt(2*np.pi) * sigma ))*(np.exp( -0.5 * ( (x-mu)/sigma )**2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume both classes are generated by a gaussian distribution. Find the decision rule by the bayes rule if:\n",
    "- Known distribution (gaussians)\n",
    "- Same variance for both classes\n",
    "- Different mean\n",
    "- Same prior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mu_0 = 6 \\\\\n",
    "\\mu_1 = 12 \\\\\n",
    "\\sigma_0 = 1 \\\\\n",
    "\\sigma_1 = 1 \\\\\n",
    "P(C_0) = P(C_1) = 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we visualize the known functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples to visualize the function\n",
    "x = np.arange(0, 100, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability density functions of each class\n",
    "pdf0 = normal_pdf(x, mu=6, sigma=1)\n",
    "pdf1 = normal_pdf(x, mu=12, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=0.85)\n",
    "# Class conditional densities (likelihoods)\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(x, pdf0)\n",
    "plt.plot(x, pdf1)\n",
    "plt.title('Likelihoods of each class (conditional densities per class)')\n",
    "plt.ylabel('p(x)')\n",
    "plt.xlabel('Feature 1 (random variable)')\n",
    "plt.legend(['p(x|c_0) ~ N(6,1)', 'p(x|c_1) ~ N(12,1)'], loc='upper right')\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define in the following box the decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define the decision function #####\n",
    "\n",
    "def x_dec_func1(x):\n",
    "    ### code\n",
    "    ### code\n",
    "    return y\n",
    "\n",
    "\n",
    "# hard-code the value of the x_dec_func1_val\n",
    "x_dec_func1_val = 9\n",
    "\n",
    "#### Define the decision function #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Known distribution\n",
    "- Same variance\n",
    "- Different mean\n",
    "- Different prior probabilities (change the threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mu_0 = 6 \\\\\n",
    "\\mu_1 = 12 \\\\\n",
    "\\sigma_0 = 1 \\\\\n",
    "\\sigma_1 = 1 \\\\\n",
    "P(C_0) = 0.75 \\\\\n",
    "P(C_1) = 0.25 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we visualize the known functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples to visualize the function\n",
    "x = np.arange(0, 100, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability density functions of each class\n",
    "pdf3 = normal_pdf(x, mu=6, sigma=1)\n",
    "pdf4 = normal_pdf(x, mu=12, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_c0 = 0.75\n",
    "prior_c1 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=0.85)\n",
    "# Class conditional densities (likelihoods)\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(x, pdf3*prior_c0)\n",
    "plt.plot(x, pdf4*prior_c1)\n",
    "plt.title('Likelihoods of each class (conditional densities per class)')\n",
    "plt.ylabel('p(x)')\n",
    "plt.xlabel('Feature 1 (random variable)')\n",
    "plt.legend(['p(x|c_3) ~ N(6,1)', 'p(x|c_4) ~ N(12,1)'], loc='upper right')\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define in the following box the decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define the decision function #####\n",
    "\n",
    "def x_dec_func2(x):\n",
    "    ### code\n",
    "    ### code\n",
    "    return y\n",
    "\n",
    "\n",
    "# hard-code the value of the x_dec_func1_val\n",
    "x_dec_func2_val = 8\n",
    "\n",
    "#### Define the decision function #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 100 random samples using the defined functions of exercise 01 and see if the decision function classify them well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 01\n",
    "# Parameters to generate the random samples comming from the parametrized distributions\n",
    "n1_samples = 100\n",
    "mu_0 = 6\n",
    "mu_1 = 12\n",
    "sigma_0 = 1\n",
    "sigma_1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 01\n",
    "# Generating 100 random samples drawn from a Normal Distribution for class 1 & 2\n",
    "x0_samples = sigma_1**0.5 * np.random.randn(n1_samples) + mu_0\n",
    "x1_samples = sigma_1**0.5 * np.random.randn(n1_samples) + mu_1\n",
    "y = [0 for i in range(n1_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample data and the decision function\n",
    "plt.scatter(x0_samples, y, marker='o', color='green', s=40, alpha=0.4)\n",
    "plt.scatter(x1_samples, y, marker='^', color='blue', s=40, alpha=0.4)\n",
    "plt.title('Binary Classification 1')\n",
    "#plt.ylabel('P(x)')\n",
    "plt.xlabel('Feature x1 (random variable)')\n",
    "plt.legend(['c_0', 'c_1'], loc='upper right')\n",
    "plt.ylim([-0.03,0.03])\n",
    "plt.xlim([0,20])\n",
    "plt.axvline(x_dec_func1_val, color='r', alpha=0.8, linestyle=':', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the empirical error of each class and for the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Build the confusion matrix ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Build the confusion matrix ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 100 random samples using the defined functions of exercise 02 and see if the decision function classify them well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 02\n",
    "# Parameters to generate the random samples comming from the parametrized distributions\n",
    "n1_samples = 50\n",
    "mu_2 = 6\n",
    "mu_3 = 12\n",
    "sigma_2 = 1\n",
    "sigma_3 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 02\n",
    "# Generating 100 random samples drawn from a Normal Distribution for class 1 & 2\n",
    "x2_samples = sigma_2**0.5 * np.random.randn(n1_samples) + mu_2\n",
    "x3_samples = sigma_3**0.5 * np.random.randn(n1_samples) + mu_3\n",
    "y = [0 for i in range(n1_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting sample data with a decision boundary\n",
    "\n",
    "plt.scatter(x2_samples, y, marker='o', color='green', s=40, alpha=0.4)\n",
    "plt.scatter(x3_samples, y, marker='^', color='blue', s=40, alpha=0.4)\n",
    "plt.title('Binary Classification 1')\n",
    "plt.xlabel('random variable x')\n",
    "plt.legend(['c_2', 'c_3'], loc='upper right')\n",
    "plt.ylim([-0.03,0.03])\n",
    "plt.xlim([0,20])\n",
    "plt.axvline(x_dec_func2_val, color='r', alpha=0.8, linestyle=':', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the empirical error of each class and for the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Build the confusion matrix ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Build the confusion matrix ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Known distribution\n",
    "- Same variance\n",
    "- Different mean\n",
    "- Same prior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mu_0 = 6 \\\\\n",
    "\\mu_1 = 12 \\\\\n",
    "\\sigma_0 = 2 \\\\\n",
    "\\sigma_1 = 2 \\\\\n",
    "P(C_0) = 0.5 \\\\\n",
    "P(C_1) = 0.5 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples to visualize the function\n",
    "x = np.arange(0, 100, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability density functions\n",
    "pdf4 = normal_pdf(x, mu=6, sigma=2)\n",
    "pdf5 = normal_pdf(x, mu=12, sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_c4 = 0.5\n",
    "prior_c5 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=0.85)\n",
    "# Class conditional densities (likelihoods)\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(x, pdf4)\n",
    "plt.plot(x, pdf5)\n",
    "plt.title('Likelihoods of each class (conditional densities per class)')\n",
    "plt.ylabel('p(x)')\n",
    "plt.xlabel('Feature 1 (random variable)')\n",
    "plt.legend(['p(x|c_4) ~ N(6,2)', 'p(x|c_5) ~ N(12,2)'], loc='upper right')\n",
    "plt.ylim([0,0.3])\n",
    "plt.xlim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the decision function in the following box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define the decision function #####\n",
    "\n",
    "def x_dec_func4(x):\n",
    "    ### code\n",
    "    ### code\n",
    "    return y\n",
    "\n",
    "\n",
    "# hard-code the value of the x_dec_func1_val\n",
    "x_dec_func4_val = 8\n",
    "\n",
    "#### Define the decision function #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Known distribution\n",
    "- Same variance\n",
    "- Different mean\n",
    "- Different prior probabilities (change the threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mu_0 = 6 \\\\\n",
    "\\mu_1 = 12 \\\\\n",
    "\\sigma_0 = 2 \\\\\n",
    "\\sigma_1 = 2 \\\\\n",
    "P(C_0) = 0.75 \\\\\n",
    "P(C_1) = 0.25 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples to visualize the function\n",
    "x = np.arange(0, 100, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability density functions\n",
    "pdf6 = normal_pdf(x, mu=6, sigma=2)\n",
    "pdf7 = normal_pdf(x, mu=12, sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_c6 = 0.75\n",
    "prior_c7 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=0.85)\n",
    "# Class conditional densities (likelihoods)\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(x, pdf6*prior_c6)\n",
    "plt.plot(x, pdf7*prior_c7)\n",
    "plt.title('Likelihoods of each class (conditional densities per class)')\n",
    "plt.ylabel('p(x)')\n",
    "plt.xlabel('Feature 1 (random variable)')\n",
    "plt.legend(['p(x|c_1) ~ N(6,2)', 'p(x|c_2) ~ N(12,2)'], loc='upper right')\n",
    "plt.ylim([0,0.3])\n",
    "plt.xlim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the decision function in the following box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define the decision function #####\n",
    "\n",
    "def x_dec_func5(x):\n",
    "    ### code\n",
    "    ### code\n",
    "    return y\n",
    "\n",
    "\n",
    "# hard-code the value of the x_dec_func1_val\n",
    "x_dec_func5_val = 8\n",
    "\n",
    "#### Define the decision function #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 100 random samples using the defined functions of exercise 04 and see if the decision function classify them well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 04\n",
    "# Parameters to generate the random samples comming from the parametrized distributions\n",
    "n1_samples = 100\n",
    "mu_4 = 6\n",
    "mu_5 = 12\n",
    "sigma_4 = 2\n",
    "sigma_5 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 04\n",
    "# Generating 100 random samples drawn from a Normal Distribution for class 1 & 2\n",
    "x4_samples = sigma_4**0.5 * np.random.randn(n1_samples) + mu_4\n",
    "x5_samples = sigma_5**0.5 * np.random.randn(n1_samples) + mu_5\n",
    "y = [0 for i in range(n1_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting sample data with a decision boundary\n",
    "\n",
    "plt.scatter(x4_samples, y, marker='o', color='green', s=40, alpha=0.4)\n",
    "plt.scatter(x5_samples, y, marker='^', color='blue', s=40, alpha=0.4)\n",
    "plt.title('Binary Classification 1')\n",
    "plt.xlabel('random variable x')\n",
    "plt.legend(['c_1', 'c_2'], loc='upper right')\n",
    "plt.ylim([-0.03,0.03])\n",
    "plt.xlim([0,20])\n",
    "plt.axvline(x_dec_func4_val, color='r', alpha=0.8, linestyle=':', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the empirical error of each class and for the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Build the confusion matrix ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Build the confusion matrix ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 100 random samples using the defined functions of exercise 05 and see if the decision function classify them well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 05\n",
    "# Parameters to generate the random samples comming from the parametrized distributions\n",
    "n1_samples = 500\n",
    "mu_6 = 6\n",
    "mu_7 = 12\n",
    "sigma_6_sqr = 2\n",
    "sigma_7_sqr = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 05\n",
    "# Generating 500 random samples drawn from a Normal Distribution for class 1 & 2\n",
    "x6_samples = sigma_6_sqr**0.5 * np.random.randn(n1_samples) + mu_6\n",
    "x7_samples = sigma_7_sqr**0.5 * np.random.randn(n1_samples) + mu_7\n",
    "y = [0 for i in range(n1_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting sample data with a decision boundary\n",
    "\n",
    "plt.scatter(x6_samples, y, marker='o', color='green', s=40, alpha=0.4)\n",
    "plt.scatter(x7_samples, y, marker='^', color='blue', s=40, alpha=0.4)\n",
    "plt.title('Classifying random example data from 2 classes')\n",
    "plt.ylabel('P(x)')\n",
    "plt.xlabel('random variable x')\n",
    "plt.legend(['c_1', 'c_2'], loc='upper right')\n",
    "plt.ylim([-0.03,0.03])\n",
    "plt.xlim([0,20])\n",
    "plt.axvline(x_dec_func5, color='r', alpha=0.8, linestyle=':', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the empirical error of each class and for the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Build the confusion matrix ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Build the confusion matrix ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Known distribution\n",
    "- Different variance\n",
    "- Different mean\n",
    "- Same prior probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mu_0 = 6 \\\\\n",
    "\\mu_1 = 12 \\\\\n",
    "\\sigma_0 = 3 \\\\\n",
    "\\sigma_1 = 1 \\\\\n",
    "P(C_0) = 0.5 \\\\\n",
    "P(C_1) = 0.5 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples to visualize the function\n",
    "x = np.arange(0, 100, 0.05)\n",
    "\n",
    "# probability density functions\n",
    "pdf8 = normal_pdf(x, mu=6, sigma=3)\n",
    "pdf9 = normal_pdf(x, mu=12, sigma=1)\n",
    "\n",
    "prior_c8 = 0.5\n",
    "prior_c9 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=0.85)\n",
    "# Class conditional densities (likelihoods)\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.plot(x, pdf8)\n",
    "plt.plot(x, pdf9)\n",
    "plt.title('Likelihoods of each class (conditional densities per class)')\n",
    "plt.xlabel('Feature 1 (random variable)')\n",
    "plt.legend(['p(x|c_1) ~ N(6,3)', 'p(x|c_2) ~ N(12,1)'], loc='upper right')\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the decision function in the following box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define the decision function #####\n",
    "\n",
    "\n",
    "\n",
    "x_dec_func7 = 0\n",
    "#### Define the decision function #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 500 random samples using the defined functions of exercise 07 and see if the decision function classify them well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 07\n",
    "# Parameters to generate the random samples comming from the parametrized distributions\n",
    "n1_samples = 500\n",
    "mu_8 = 6\n",
    "mu_9 = 12\n",
    "sigma_8_sqr = 3\n",
    "sigma_9_sqr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 07\n",
    "# Generating 500 random samples drawn from a Normal Distribution for class 1 & 2\n",
    "x8_samples = sigma_8_sqr**0.5 * np.random.randn(n1_samples) + mu_8\n",
    "x9_samples = sigma_9_sqr**0.5 * np.random.randn(n1_samples) + mu_9\n",
    "y = [0 for i in range(n1_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting sample data with a decision boundary\n",
    "\n",
    "plt.scatter(x8_samples, y, marker='o', color='green', s=40, alpha=0.4)\n",
    "plt.scatter(x9_samples, y, marker='^', color='blue', s=40, alpha=0.4)\n",
    "plt.title('Classifying random example data from 2 classes')\n",
    "plt.ylabel('P(x)')\n",
    "plt.xlabel('random variable x')\n",
    "plt.legend(['c_1', 'c_2'], loc='upper right')\n",
    "plt.ylim([-0.03,0.03])\n",
    "plt.xlim([0,20])\n",
    "plt.axvline(x_dec_func7, color='r', alpha=0.8, linestyle=':', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the empirical error of each class and for the whole experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Build the confusion matrix ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Build the confusion matrix ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Known distribution\n",
    "- Equal variance\n",
    "- Different mean\n",
    "- Same prior probabilities\n",
    "- two features!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "M_0 = [0,0] \\\\\n",
    "M_1 = [2,2] \\\\\n",
    "\\Sigma_0 = [[1,0],[0,1]] \\\\\n",
    "\\Sigma_1 = [[1,0],[0,1]] \\\\\n",
    "P(C_0) = 0.5 \\\\\n",
    "P(C_1) = 0.5 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of function 0\n",
    "mean0 = np.array([0,0])\n",
    "cov0 = np.array([[1,0],[0,1]])\n",
    "\n",
    "# parameters of function 1\n",
    "mean1 = np.array([2,2])\n",
    "cov1 = np.array([[1,0],[0,1]])\n",
    "\n",
    "# generate 400 samples of each class\n",
    "n1_samples = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define the decision function #####\n",
    "\n",
    "\n",
    "\n",
    "x_dec_func9 = 0\n",
    "#### Define the decision function #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 100 random samples for class0\n",
    "x0_samples_2d = np.random.multivariate_normal(mean0, cov0, n1_samples)\n",
    "mean0 = mean0.reshape(1,2).T # to 1-col vector\n",
    "\n",
    "# Generate 100 random samples for class1\n",
    "x1_samples_2d = np.random.multivariate_normal(mean1, cov1, n1_samples)\n",
    "mean1 = mean1.reshape(1,2).T # to 1-col vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the random samples obtained from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(x0_samples_2d[:,0], x0_samples_2d[:,1], marker='o', color='green', s=40, alpha=0.5)\n",
    "ax.scatter(x1_samples_2d[:,0], x1_samples_2d[:,1], marker='^', color='blue', s=40, alpha=0.5)\n",
    "plt.legend(['Class1 (c1)', 'Class2 (c2)'], loc='upper right') \n",
    "plt.title('Densities of 2 classes with 400 random samples')\n",
    "plt.ylabel('x2')\n",
    "plt.xlabel('x1')\n",
    "plt.ylim([-3,6])\n",
    "plt.xlim([-3,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 100 random samples using the defined functions of exercise 05 and see if the decision function classify them well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 05\n",
    "# Parameters to generate the random samples comming from the parametrized distributions\n",
    "n1_samples = 500\n",
    "mu_6 = 6\n",
    "mu_7 = 12\n",
    "sigma_6_sqr = 1\n",
    "sigma_7_sqr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dec_func5 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For exercise 02\n",
    "# Generating 100 random samples drawn from a Normal Distribution for class 1 & 2\n",
    "x6_samples = sigma_6_sqr**0.5 * np.random.randn(n1_samples) + mu_6\n",
    "x7_samples = sigma_7_sqr**0.5 * np.random.randn(n1_samples) + mu_7\n",
    "y = [0 for i in range(n1_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting sample data with a decision boundary\n",
    "\n",
    "plt.scatter(x6_samples, y, marker='o', color='green', s=40, alpha=0.4)\n",
    "plt.scatter(x7_samples, y, marker='^', color='blue', s=40, alpha=0.4)\n",
    "plt.title('Classifying random example data from 2 classes')\n",
    "plt.ylabel('P(x)')\n",
    "plt.xlabel('random variable x')\n",
    "plt.legend(['c_1', 'c_2'], loc='upper right')\n",
    "plt.ylim([-0.03,0.03])\n",
    "plt.xlim([0,20])\n",
    "plt.axvline(x_dec_func5, color='r', alpha=0.8, linestyle=':', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Compute the empirical error for each class and for the whole system of the proposed decision function #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Build the confusion matrix ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### Build the confusion matrix ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we know the underlying conditional probability density function (Gaussian) but we need to determine which parameters characterize this function. The parameters are obtained via the data samples generated by this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the MLE for \\mu vector estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input x_samples (numpy array). Every sample is a row and the features (dimensions) are columns.\n",
    "def mle_gauss_mu(x_samples):\n",
    "    dims = x_samples.shape[1]\n",
    "    mu_est = np.zeros((dims,1))\n",
    "    for dim in range(dims):\n",
    "        col_mean = sum(x_samples[:,dim])/len(x_samples[:,dim])\n",
    "        mu_est[dim] = col_mean\n",
    "    return mu_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the MLE for \\Sigma matrix estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate co-variance matrix\n",
    "def mle_gauss_cov(x_samples, mu_est):\n",
    "    dims = samples.shape[1]\n",
    "    cov_est = np.zeros((dims,dims))\n",
    "    for x_vec in samples:\n",
    "        x_vec = x_vec.reshape(dims,1)\n",
    "        cov_est += (x_vec - mu_est).dot((x_vec - mu_est).T)\n",
    "    return cov_est / len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the true function 0\n",
    "mean10_0 = np.array([0,0])\n",
    "cov10_0 = np.array([[1,0],[0,1]])\n",
    "\n",
    "# parameters of the true function 1\n",
    "mean10_1 = np.array([2,2])\n",
    "cov10_1 = np.array([[1,0],[0,1]])\n",
    "\n",
    "# generate 100 samples of each class\n",
    "n1_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 100 random samples for class0\n",
    "x0_samples_2d = np.random.multivariate_normal(mean10_0, cov10_0, n1_samples)\n",
    "\n",
    "# Generate 100 random samples for class1\n",
    "x1_samples_2d = np.random.multivariate_normal(mean10_1, cov10_0, n1_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the mu vector and sigma matrix for each distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Estimate the mu vectors here. Use the defined function mle_gauss_mu #######\n",
    "mu_mle0 = \n",
    "mu_mle1 = \n",
    "###### Estimate the mu vectors here. Use the defined function mle_gauss_mu #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Estimate the sigma matrices here. Use the defined function mle_gauss_mu #######\n",
    "sigma_mle0 = \n",
    "sigma_mle1 = \n",
    "###### Estimate the sigma matrices here. Use the defined function mle_gauss_mu #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_mle = mle_gauss_mu(x0_samples_2d)\n",
    "mu_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Compare the estimated parameters with the true ones using 10,40,60,100 and 1000 samples #######\n",
    "\n",
    "# code here\n",
    "\n",
    "###### Compare the estimated parameters with the true ones using 10,40,60,100 and 1000 samples #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Using the estimated parameters with 100 samples generate a decision boundary with the Bayes Rule #####\n",
    "\n",
    "# code here\n",
    "\n",
    "###### Using the estimated parameters with 100 samples generate a decision boundary with the Bayes Rule #####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
